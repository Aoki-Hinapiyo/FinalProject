import os
import json
import librosa
import numpy as np
import openl3
from collections import Counter
from sklearn.metrics.pairwise import cosine_similarity

# ===== å‚æ•°é…ç½® =====
FEATURE_JSON = r"E:\GitProject\FinalProject\features.json"
SAMPLE_RATE = 48000
EMBEDDING_SIZE = 6144
WINDOW_SIZE = 3.0  # æ¯ä¸ªåˆ‡ç‰‡çš„é•¿åº¦ï¼ˆç§’ï¼‰
HOP_SIZE = 1.0     # æ»‘åŠ¨æ­¥é•¿ï¼ˆç§’ï¼‰
TOP_K = 3          # è¾“å‡º Top-k åŒ¹é…ç»“æœ

# ===== åŠ è½½æ¨¡å‹ =====
model = openl3.models.load_audio_embedding_model(
    input_repr="mel256", content_type="music", embedding_size=EMBEDDING_SIZE
)

# ===== éŸ³é¢‘é¢„å¤„ç†å‡½æ•° =====
def preprocess_audio(y, sr):
    if y.ndim > 1:
        y = librosa.to_mono(y)
    y = librosa.util.normalize(y)
    y = librosa.effects.preemphasis(y)
    return y

# ===== å•æ®µæå– OpenL3 ç‰¹å¾ =====
def extract_feature(y, sr):
    emb, _ = openl3.get_audio_embedding(y, sr, model=model, center=True, hop_size=1.0)
    return np.mean(emb, axis=0)

# ===== åŠ è½½ç‰¹å¾åº“ =====
def load_feature_database():
    with open(FEATURE_JSON, "r", encoding="utf-8") as f:
        db = json.load(f)
    names, artists, sources, features = [], [], [], []
    for file, meta in db.items():
        names.append(meta["Name"])
        artists.append(meta["Artist"])
        sources.append(meta["Source"])
        features.append(meta["Feature"])
    features = np.array(features, dtype=np.float32)
    return names, artists, sources, features

# ===== æ»‘åŠ¨çª—å£è¯†åˆ«å‡½æ•° =====
def recognize_sliding(input_path):
    print(f"\n[INFO] æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼š{input_path}")
    # sf.info() æ³¨é‡Šï¼Œé¿å… .m4a æŠ¥é”™
    # info = sf.info(input_path)
    # print(f"é‡‡æ ·ç‡: {info.samplerate} | å£°é“: {info.channels} | æ—¶é•¿: {round(info.duration,2)} ç§’")

    y, _ = librosa.load(input_path, sr=SAMPLE_RATE, mono=False)
    y = preprocess_audio(y, SAMPLE_RATE)

    names, artists, sources, db_features = load_feature_database()

    matches = []
    times = []

    total_duration = len(y) / SAMPLE_RATE
    for start in np.arange(0, total_duration - WINDOW_SIZE, HOP_SIZE):
        y_seg = y[int(start * SAMPLE_RATE): int((start + WINDOW_SIZE) * SAMPLE_RATE)]
        if len(y_seg) < SAMPLE_RATE * WINDOW_SIZE:
            continue
        vec = extract_feature(y_seg, SAMPLE_RATE).reshape(1, -1)
        sims = cosine_similarity(vec, db_features)[0]
        top_idx = sims.argmax()
        matches.append(names[top_idx])
        times.append((start, start + WINDOW_SIZE))
        print(f"[{round(start,1)}s - {round(start+WINDOW_SIZE,1)}s] â†’ åŒ¹é…: {names[top_idx]} | åŒ¹é…ç‡: {sims[top_idx]*100:.2f}%")

    print("\nğŸ“Š Top åŒ¹é…ç»Ÿè®¡ï¼ˆæŠ•ç¥¨æœºåˆ¶ï¼‰:")
    counter = Counter(matches)
    for name, count in counter.most_common(TOP_K):
        print(f"{name} å‡ºç° {count} æ¬¡")

if __name__ == "__main__":
    path = input("è¯·è¾“å…¥è¦è¯†åˆ«çš„éŸ³é¢‘è·¯å¾„ï¼š").strip('"')
    if not os.path.exists(path):
        print("âŒ è¾“å…¥è·¯å¾„æ— æ•ˆï¼Œè¯·æ£€æŸ¥ã€‚")
    else:
        recognize_sliding(path)
